# -*- coding: utf-8 -*-
"""thresh2_oct15b.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OfLDgnnWYCl7yrfWke9Eazt2TFVZgn6A
"""





"""**Full workflow**"""

import numpy as np
import pandas as pd
from datetime import datetime, timedelta

# Simulate H3 hierarchy without the h3 library
def simulate_h3_to_parent(res8_cell, target_res):
    """Simulate getting parent cell by truncating the cell ID"""
    # In real H3, res3 cells are parents of res8 cells
    # We'll simulate this by using prefixes
    return res8_cell[:12]  # Simulate res3 as prefix of res8

def simulate_h3_children(res3_cell, target_res):
    """Simulate getting child cells by appending suffixes"""
    # Generate some fake res8 children for a res3 parent
    children = []
    for i in range(5):  # Generate 5 children per parent
        children.append(res3_cell + f"_{i:03d}")
    return children

# ===== STEP 1: Generate toy data (simulating 10 days of thresholds) =====
print("=" * 60)
print("STEP 1: Generating 10 days of res3 threshold data")
print("=" * 60)

# Create sample res3 cells (H3 resolution 3 hexagons)
sample_res3_cells = [
    '831f91ffffff',  # Simulated H3 res3 cell
    '831f93ffffff',
    '831f95ffffff',
    '831f97ffffff',
]

# Generate 10 days of threshold data for res3 cells
dates = [(datetime(2025, 1, 1) + timedelta(days=i)).strftime('%Y-%m-%d')
         for i in range(10)]

# Simulate running thresholding() for 10 days
all_res3_thresholds = []

for date in dates:
    for h3_3 in sample_res3_cells:
        # Simulate thresholds with some daily variation
        base_t1 = np.random.uniform(50, 150)
        daily_noise = np.random.uniform(0.9, 1.1)

        all_res3_thresholds.append({
            'date': date,
            'h3_3': h3_3,
            'country': 'US',
            'threshold_1': base_t1 * daily_noise,
            'threshold_3': base_t1 * 0.8 * daily_noise,
            'threshold_5': base_t1 * 0.6 * daily_noise
        })

df_res3_thresholds = pd.DataFrame(all_res3_thresholds)
print(f"\nGenerated {len(df_res3_thresholds)} res3 threshold records")
print(f"Date range: {df_res3_thresholds['date'].min()} to {df_res3_thresholds['date'].max()}")
print(f"\nSample of res3 thresholds:")
print(df_res3_thresholds.head(10))

# ===== STEP 2: Create asset (res8) cells =====
print("\n" + "=" * 60)
print("STEP 2: Creating asset cells (res8)")
print("=" * 60)

# Create sample assets with res8 H3 cells
# These are children of the res3 cells above
assets_data = []

for res3_cell in sample_res3_cells[:2]:  # Use first 2 res3 cells
    # Generate res8 children for each res3 parent
    # In reality, each res3 has many res8 children
    res8_children = simulate_h3_children(res3_cell, 8)

    # Take just a few for the toy example
    for i, res8_cell in enumerate(res8_children[:3]):
        assets_data.append({
            'title': f'Asset_{res3_cell[-4:]}_{i}',
            'h3': res8_cell,
            'country': 'US'
        })

df_assets = pd.DataFrame(assets_data)
print(f"\nCreated {len(df_assets)} assets")
print(df_assets)

# ===== STEP 3: Map assets to their parent res3 cells =====
print("\n" + "=" * 60)
print("STEP 3: Mapping assets to parent res3 cells")
print("=" * 60)

df_assets['h3_3'] = df_assets['h3'].apply(lambda x: simulate_h3_to_parent(x, 3))
print("\nAssets with parent res3 cells:")
print(df_assets[['title', 'h3', 'h3_3']])

# ===== STEP 4: Average thresholds over 10 days for each res3 cell =====
print("\n" + "=" * 60)
print("STEP 4: Averaging thresholds over 10-day period")
print("=" * 60)

# Calculate average thresholds for each res3 cell over the 10-day period
df_avg_thresholds = df_res3_thresholds.groupby(['h3_3', 'country']).agg({
    'threshold_1': 'mean',
    'threshold_3': 'mean',
    'threshold_5': 'mean'
}).reset_index()

print("\nAverage thresholds per res3 cell (10-day average):")
print(df_avg_thresholds)

# ===== STEP 5: Assign averaged thresholds to assets =====
print("\n" + "=" * 60)
print("STEP 5: Assigning averaged thresholds to assets")
print("=" * 60)

# Merge assets with their parent res3 averaged thresholds
df_final = df_assets.merge(
    df_avg_thresholds,
    on=['h3_3', 'country'],
    how='left'
)

print("\nFinal asset thresholds (inherited from 10-day res3 averages):")
print(df_final[['title', 'h3_3', 'threshold_1', 'threshold_3', 'threshold_5']])

# ===== STEP 6: Show the logic more clearly =====
print("\n" + "=" * 60)
print("SUMMARY: What we did")
print("=" * 60)

print("""
1. Generated 10 days of threshold data for res3 cells
   - Each res3 cell has thresholds calculated daily
   - This simulates running thresholding() 10 times

2. Created asset cells at res8 resolution
   - Assets are much more granular than res3 regions

3. Mapped each asset (res8) to its parent res3 cell
   - Used simulate_h3_to_parent(res8_cell, 3)
   - In real code: h3.h3_to_parent(res8_cell, 3)

4. Averaged thresholds over 10 days for each res3 cell
   - grouped by (h3_3, country)
   - calculated mean of threshold_1, threshold_3, threshold_5

5. Assigned these averaged thresholds to all child assets
   - Each asset inherits the 10-day average from its parent res3
""")

# ===== Optional: Show variation over time =====
print("\n" + "=" * 60)
print("BONUS: Threshold variation over time")
print("=" * 60)

sample_cell = sample_res3_cells[0]
df_sample = df_res3_thresholds[df_res3_thresholds['h3_3'] == sample_cell]
print(f"\nThreshold_1 for cell {sample_cell} over 10 days:")
print(df_sample[['date', 'threshold_1']].to_string(index=False))
print(f"\n10-day average: {df_sample['threshold_1'].mean():.2f}")
print(f"Standard deviation: {df_sample['threshold_1'].std():.2f}")





"""**Updated multi-thresholding (70%, 50%, 10%)**"""



import numpy as np
import pandas as pd
from datetime import datetime, timedelta

# ===== CONFIGURATION: Multi-threshold severity levels =====
THRESHOLD_LEVELS = {
    'threshold_high': 0.70,    # 70% - Most sensitive (High severity alerts)
    'threshold_medium': 0.50,  # 50% - Medium sensitivity (Medium severity)
    'threshold_low': 0.10      # 10% - Least sensitive (Low severity/informational)
}

print("=" * 60)
print("MULTI-THRESHOLD CONFIGURATION")
print("=" * 60)
print("\nSeverity levels (as % of base threshold):")
for name, pct in THRESHOLD_LEVELS.items():
    print(f"  {name}: {pct*100:.0f}%")

# Simulate H3 hierarchy without the h3 library
def simulate_h3_to_parent(res8_cell, target_res):
    """Simulate getting parent cell by truncating the cell ID"""
    return res8_cell[:12]

def simulate_h3_children(res3_cell, target_res):
    """Simulate getting child cells by appending suffixes"""
    children = []
    for i in range(5):
        children.append(res3_cell + f"_{i:03d}")
    return children

# ===== STEP 1: Generate toy data (simulating 10 days of thresholds) =====
print("\n" + "=" * 60)
print("STEP 1: Generating 10 days of res3 threshold data")
print("=" * 60)

sample_res3_cells = [
    '831f91ffffff',
    '831f93ffffff',
    '831f95ffffff',
    '831f97ffffff',
]

dates = [(datetime(2025, 1, 1) + timedelta(days=i)).strftime('%Y-%m-%d')
         for i in range(10)]

all_res3_thresholds = []

for date in dates:
    for h3_3 in sample_res3_cells:
        # Base threshold calculation
        base_threshold = np.random.uniform(50, 150)
        daily_noise = np.random.uniform(0.9, 1.1)

        # Apply noise to base threshold
        base_with_noise = base_threshold * daily_noise

        # Calculate multiple severity levels
        all_res3_thresholds.append({
            'date': date,
            'h3_3': h3_3,
            'country': 'US',
            'base_threshold': base_with_noise,
            'threshold_high': base_with_noise * THRESHOLD_LEVELS['threshold_high'],
            'threshold_medium': base_with_noise * THRESHOLD_LEVELS['threshold_medium'],
            'threshold_low': base_with_noise * THRESHOLD_LEVELS['threshold_low']
        })

df_res3_thresholds = pd.DataFrame(all_res3_thresholds)
print(f"\nGenerated {len(df_res3_thresholds)} res3 threshold records")
print(f"Date range: {df_res3_thresholds['date'].min()} to {df_res3_thresholds['date'].max()}")
print(f"\nSample with all severity levels:")
print(df_res3_thresholds.head(5))

# ===== STEP 2: Create asset (res8) cells =====
print("\n" + "=" * 60)
print("STEP 2: Creating asset cells (res8)")
print("=" * 60)

assets_data = []

for res3_cell in sample_res3_cells[:2]:
    res8_children = simulate_h3_children(res3_cell, 8)

    for i, res8_cell in enumerate(res8_children[:3]):
        assets_data.append({
            'title': f'Asset_{res3_cell[-4:]}_{i}',
            'h3': res8_cell,
            'country': 'US'
        })

df_assets = pd.DataFrame(assets_data)
print(f"\nCreated {len(df_assets)} assets")

# ===== STEP 3: Map assets to their parent res3 cells =====
print("\n" + "=" * 60)
print("STEP 3: Mapping assets to parent res3 cells")
print("=" * 60)

df_assets['h3_3'] = df_assets['h3'].apply(lambda x: simulate_h3_to_parent(x, 3))
print("\nAssets with parent res3 cells:")
print(df_assets[['title', 'h3_3']])

# ===== STEP 4: Average thresholds over 10 days for each res3 cell =====
print("\n" + "=" * 60)
print("STEP 4: Averaging ALL threshold levels over 10-day period")
print("=" * 60)

df_avg_thresholds = df_res3_thresholds.groupby(['h3_3', 'country']).agg({
    'base_threshold': 'mean',
    'threshold_high': 'mean',
    'threshold_medium': 'mean',
    'threshold_low': 'mean'
}).reset_index()

print("\nAverage thresholds per res3 cell (10-day average, all severity levels):")
print(df_avg_thresholds)

# ===== STEP 5: Assign averaged thresholds to assets =====
print("\n" + "=" * 60)
print("STEP 5: Assigning averaged thresholds to assets")
print("=" * 60)

df_final = df_assets.merge(
    df_avg_thresholds,
    on=['h3_3', 'country'],
    how='left'
)

print("\nFinal asset thresholds with all severity levels:")
print(df_final[['title', 'h3_3', 'threshold_high', 'threshold_medium', 'threshold_low']])

# ===== STEP 6: Calculate volatility flags =====
print("\n" + "=" * 60)
print("STEP 6: Calculating volatility flags")
print("=" * 60)

volatility_threshold = 10  # Threshold for high variability

volatility_df = df_res3_thresholds.groupby('h3_3')['base_threshold'].std().reset_index()
volatility_df['is_volatile'] = volatility_df['base_threshold'] > volatility_threshold
volatility_df = volatility_df.rename(columns={'base_threshold': 'threshold_std'})

df_final = df_final.merge(volatility_df[['h3_3', 'threshold_std', 'is_volatile']], on='h3_3', how='left')

print("\nFinal output with volatility flags:")
print(df_final[['title', 'h3_3', 'threshold_high', 'threshold_medium', 'threshold_low', 'is_volatile']])

# ===== STEP 7: Demonstration of severity-based alerting =====
print("\n" + "=" * 60)
print("STEP 7: Example - How to use multi-thresholds for alerting")
print("=" * 60)

# Simulate some current scores for assets
np.random.seed(42)
df_final['current_score'] = np.random.uniform(20, 100, len(df_final))

def check_alert_level(row):
    """Determine alert severity based on current score"""
    if row['current_score'] > row['threshold_high']:
        return 'HIGH_SEVERITY'
    elif row['current_score'] > row['threshold_medium']:
        return 'MEDIUM_SEVERITY'
    elif row['current_score'] > row['threshold_low']:
        return 'LOW_SEVERITY'
    else:
        return 'NO_ALERT'

df_final['alert_level'] = df_final.apply(check_alert_level, axis=1)

print("\nAsset alerting example:")
print(df_final[['title', 'current_score', 'threshold_low', 'threshold_medium',
                'threshold_high', 'alert_level', 'is_volatile']])

# ===== STEP 8: Summary statistics =====
print("\n" + "=" * 60)
print("SUMMARY STATISTICS")
print("=" * 60)

print(f"\n1. Total assets monitored: {len(df_final)}")
print(f"\n2. Alert distribution:")
alert_counts = df_final['alert_level'].value_counts()
for level, count in alert_counts.items():
    print(f"   - {level}: {count}")

print(f"\n3. Volatile regions: {df_final['is_volatile'].sum()} out of {len(df_final)} assets")

print(f"\n4. Threshold ranges across all assets:")
print(f"   - High severity (70%): {df_final['threshold_high'].min():.2f} to {df_final['threshold_high'].max():.2f}")
print(f"   - Medium severity (50%): {df_final['threshold_medium'].min():.2f} to {df_final['threshold_medium'].max():.2f}")
print(f"   - Low severity (10%): {df_final['threshold_low'].min():.2f} to {df_final['threshold_low'].max():.2f}")

# ===== STEP 9: Show variation over time for one cell =====
print("\n" + "=" * 60)
print("BONUS: Threshold variation over time (demonstrating why averaging helps)")
print("=" * 60)

sample_cell = sample_res3_cells[0]
df_sample = df_res3_thresholds[df_res3_thresholds['h3_3'] == sample_cell]

print(f"\nCell: {sample_cell}")
print("\nBase threshold over 10 days:")
print(df_sample[['date', 'base_threshold', 'threshold_high', 'threshold_medium', 'threshold_low']].to_string(index=False))

print(f"\n10-day averages:")
print(f"  Base: {df_sample['base_threshold'].mean():.2f}")
print(f"  High (70%): {df_sample['threshold_high'].mean():.2f}")
print(f"  Medium (50%): {df_sample['threshold_medium'].mean():.2f}")
print(f"  Low (10%): {df_sample['threshold_low'].mean():.2f}")

print(f"\nStandard deviation: {df_sample['base_threshold'].std():.2f}")
print(f"Volatility flag: {df_final[df_final['h3_3'] == sample_cell]['is_volatile'].values[0]}")

print("\n" + "=" * 60)
print("COMPLETE: Multi-threshold system with 10-day averaging")
print("=" * 60)







