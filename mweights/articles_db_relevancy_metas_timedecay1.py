# -*- coding: utf-8 -*-
"""articles_db_relevancy_metas_timedecay1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1roY-eY5xpacrxZDZ2CnafqrJCHTCoQSU
"""







import pandas as pd



"""**Translated articles+metadata**"""





"""
Microweight System with Temporal Decay
Uses your actual CSV files with timestamps
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from collections import defaultdict

print("="*80)
print("MICROWEIGHT SYSTEM WITH TEMPORAL DECAY")
print("="*80)

# Load relevancy feedback
relevance_df = pd.read_csv('/translated_articles_relevance.csv',
                           header=None,
                           names=['article_id', 'relevant', 'org_id', 'asset_id', 'incident_id'])

# Load article metadata (has timestamps!)
articles_df = pd.read_csv('/found_articles_nov24a.csv')
articles_df['utc_datetime'] = pd.to_datetime(articles_df['utc_datetime'])

print(f"\n✓ Loaded {len(relevance_df)} relevancy marks")
print(f"✓ Loaded {len(articles_df)} articles with timestamps")

# Merge to get timestamps for relevant marks
merged = relevance_df.merge(
    articles_df[['id', 'utc_datetime', 'category', 'sourcecountry']],
    left_on='article_id',
    right_on='id',
    how='left'
)

# Filter to TRUE marks only
true_marks = merged[merged['relevant'] == True].copy()
true_marks = true_marks.dropna(subset=['utc_datetime'])

print(f"✓ Matched {len(true_marks)} TRUE marks with timestamps")

if len(true_marks) == 0:
    print("\n⚠️  No TRUE marks matched with article timestamps")
    print("Cannot apply temporal decay without timestamps")
else:
    # Configuration
    DECAY_RATE = 0.05  # 5% daily decay
    LEARNING_RATE = 0.1  # 10% learning per click
    BASELINE = 1.0
    MAX_WEIGHT = 2.0

    print(f"\nDecay Configuration:")
    print(f"  Decay rate: {DECAY_RATE} (5% daily)")
    print(f"  Learning rate: {LEARNING_RATE} (10% per mark)")
    print(f"  Baseline: {BASELINE}")
    print(f"  Max weight: {MAX_WEIGHT}")

    # Reference date (use latest article date)
    reference_date = articles_df['utc_datetime'].max()
    print(f"  Reference date: {reference_date}")

    # Calculate microweights with temporal decay for each asset
    print("\n" + "="*80)
    print("ASSET-SPECIFIC MICROWEIGHTS WITH DECAY")
    print("="*80)

    asset_weights = {}

    for asset_id in sorted(true_marks['asset_id'].unique()):
        asset_marks = true_marks[true_marks['asset_id'] == asset_id].copy()
        asset_marks = asset_marks.sort_values('utc_datetime')

        print(f"\n{'='*80}")
        print(f"ASSET {asset_id}")
        print(f"{'='*80}")

        # Initialize weights
        category_weights = defaultdict(lambda: BASELINE)
        country_weights = defaultdict(lambda: BASELINE)

        # Process each mark chronologically
        for idx, mark in asset_marks.iterrows():
            category = mark['category']
            country = mark['sourcecountry']
            mark_date = mark['utc_datetime']

            # Apply learning
            if pd.notna(category):
                old_weight = category_weights[category]
                category_weights[category] = old_weight + LEARNING_RATE * (MAX_WEIGHT - old_weight)

            if pd.notna(country):
                old_weight = country_weights[country]
                country_weights[country] = old_weight + LEARNING_RATE * (MAX_WEIGHT - old_weight)

            print(f"\n  Mark from {mark_date.date()}:")
            print(f"    Article: {mark['article_id']}")
            print(f"    Category: {category} → weight: {category_weights[category]:.3f}")
            print(f"    Country: {country} → weight: {country_weights[country]:.3f}")

        # Apply temporal decay based on time since last mark
        last_mark_date = asset_marks['utc_datetime'].max()
        days_elapsed = (reference_date - last_mark_date).days

        print(f"\n  Applying decay:")
        print(f"    Days since last mark: {days_elapsed}")
        print(f"    Decay factor: {(1 - DECAY_RATE) ** days_elapsed:.3f}")

        # Apply decay to all weights
        decay_factor = (1 - DECAY_RATE) ** days_elapsed

        decayed_category_weights = {}
        for cat, weight in category_weights.items():
            diff = weight - BASELINE
            decayed_weight = BASELINE + diff * decay_factor
            decayed_category_weights[cat] = decayed_weight

        decayed_country_weights = {}
        for country, weight in country_weights.items():
            diff = weight - BASELINE
            decayed_weight = BASELINE + diff * decay_factor
            decayed_country_weights[country] = decayed_weight

        print(f"\n  Final weights after decay:")
        print(f"    Top categories:")
        for cat, weight in sorted(decayed_category_weights.items(),
                                  key=lambda x: x[1], reverse=True)[:3]:
            print(f"      {cat}: {weight:.3f}")

        print(f"    Top countries:")
        for country, weight in sorted(decayed_country_weights.items(),
                                     key=lambda x: x[1], reverse=True)[:3]:
            print(f"      {country}: {weight:.3f}")

        # Store for this asset
        asset_weights[asset_id] = {
            'category_weights': decayed_category_weights,
            'country_weights': decayed_country_weights,
            'last_mark_date': last_mark_date,
            'total_marks': len(asset_marks)
        }

    # Summary comparison
    print("\n" + "="*80)
    print("SUMMARY: WEIGHTS WITH vs WITHOUT DECAY")
    print("="*80)

    for asset_id, weights in asset_weights.items():
        print(f"\nAsset {asset_id}:")
        print(f"  Total marks: {weights['total_marks']}")
        print(f"  Last activity: {weights['last_mark_date'].date()}")
        print(f"  Days ago: {(reference_date - weights['last_mark_date']).days}")

        # Show decay impact
        if weights['category_weights']:
            top_cat = max(weights['category_weights'].items(), key=lambda x: x[1])
            no_decay_weight = BASELINE + LEARNING_RATE * weights['total_marks']
            print(f"  Top category: {top_cat[0]}")
            print(f"    Without decay: ~{min(no_decay_weight, MAX_WEIGHT):.3f}")
            print(f"    With decay: {top_cat[1]:.3f}")
            print(f"    Decay impact: {((min(no_decay_weight, MAX_WEIGHT) - top_cat[1]) / min(no_decay_weight, MAX_WEIGHT) * 100):.1f}% reduction")

    print("\n" + "="*80)
    print("✓ TEMPORAL DECAY APPLIED")
    print("="*80)
    print("\nKey insights:")
    print("  • Recent marks have full weight impact")
    print("  • Older marks decay over time (5% daily)")
    print("  • Prevents overindexing on old preferences")
    print("  • Weights naturally return to baseline if no new activity")

print("\n" + "="*80)
print("✓ COMPLETE")
print("="*80)







